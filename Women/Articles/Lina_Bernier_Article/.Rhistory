barplot(100 * table(fannie_mae_sample$relocation)/5000, ylim=c(0,100), ylab = "%",  main = "Distribution of relocation indicator"); grid()
barplot(100 * table(fannie_mae_sample$first_time)/5000, ylim=c(0,80), ylab = "%",  main = "Distribution of first-time buyer indicator"); grid()
num_rows <- nrow(fannie_mae)
# We will split the data 70-30.
set.seed(123)
training_indexes <- sample(x = seq(num_rows), size = floor(0.7 * num_rows)) # sampling 70% of the data
fannie_mae_training <- fannie_mae[training_indexes,]
fannie_mae_test <- fannie_mae[-training_indexes,] # notice the -index!
lm.fit.linear <- lm(interest ~ balance + dti + ltv + borrower_score + co_borrower_score + purpose + property_type + relocation + first_time, data = fannie_mae_training )
summary(lm.fit.linear)
summary(lm.fit.linear)$coefficients
# Compute degrees of freedom for the t-distribution
# df = num of observations minus num of coefficients, including intercept
num_rows_training <- nrow(fannie_mae_training)
degrees_of_freedom <- num_rows_training - 15
# Compute p-value. We multiply by 2 because we want Pr(t > 11.92541 or t < -11.92541)
t_val <- summary(lm.fit.linear)$coefficients["balance",][1] / summary(lm.fit.linear)$coefficients["balance",][2]
p_value <- pt(t_val, df = degrees_of_freedom, lower.tail = TRUE) * 2
residuals(lm.fit.linear) %>% hist()
linear_model_residuals <- residuals(lm.fit.linear)
linear_model_fitted <- fitted.values(lm.fit.linear)
plot(linear_model_fitted, linear_model_residuals, col="darkgrey", xlab = "Linear model fitted values", ylab = "Linear model residuals", main = "Residuals variability plot for linear model")
abline(h = 0, lty = 3)
lm.fit.linear.residuals <- lm(linear_model_residuals ~ poly(linear_model_fitted, 3, raw = TRUE), data=fannie_mae_training)
predicted_lims <- range(fitted.values(lm.fit.linear))
predicted_lims.grid <- seq(from = predicted_lims[1], to = predicted_lims[2], by = 0.005)
preds_lm_linear_residuals <- predict(lm.fit.linear.residuals, data.frame(linear_model_fitted=predicted_lims.grid), se = TRUE) # predictions
se_bands_linear_residuals <- cbind(preds_lm_linear_residuals$fit + 2 * preds_lm_linear_residuals$se, preds_lm_linear_residuals$fit - 2 * preds_lm_linear_residuals$se) # standard error bands
lines(predicted_lims.grid, preds_lm_linear_residuals$fit, col = "darkred", lwd = 2)
matlines(predicted_lims.grid, se_bands_linear_residuals, col = "darkblue", lty = 2)
library(lmtest)
bptest.linear <- bptest(lm.fit.linear)
bptest.linear
lm.fit.linear.residuals.squared <- lm(linear_model_residuals^2 ~ balance + dti + ltv + borrower_score + co_borrower_score + purpose + property_type + relocation + first_time, data = fannie_mae_training)
BP_test_statistic <- length(linear_model_residuals) * summary(lm.fit.linear.residuals.squared)$r.squared
RSS <- residuals(lm.fit.linear)^2 %>% sum()
MSE <- RSS / num_rows_training
interest_mean <- mean(fannie_mae_training$interest)
TSS <- (fannie_mae_training$interest - interest_mean)^2 %>% sum()
R_sqrd <- 1 - RSS / TSS
num_predictors <- coefficients(lm.fit.linear) %>% length() - 1 # the intercept does not count
Adjusted_R_sqrd <- 1 - RSS / TSS * (num_rows_training - 1) / (num_rows_training - num_predictors - 1)
num_predictors <- coefficients(lm.fit.linear) %>% length() - 1 # the intercept does not count
F <- ((TSS - RSS) / num_predictors) / (RSS / (num_rows_training - num_predictors - 1))
# Predictions vector
predict_interest_test <- predict(lm.fit.linear, newdata = fannie_mae_test)
# Compute RSS on test set
RSS_test <- (fannie_mae_test$interest - predict_interest_test)^2 %>% sum()
# Compute TSS on test set using mean of interest rates of *training* set
TSS_test <- (fannie_mae_test$interest - interest_mean)^2 %>% sum()
R_sqrd_test <- 1 - RSS_test / TSS_test
# Compute MSE on test set
num_rows_test <- nrow(fannie_mae_test)
MSE_test <- RSS_test / num_rows_test
lm.fit.ltv.1 <- lm(interest ~ ltv, data=fannie_mae_training)
lm.fit.ltv.2 <- lm(interest ~ poly(ltv, 2, raw = TRUE), data=fannie_mae_training)
RSS_1 <- residuals(lm.fit.ltv.1)^2 %>% sum()
RSS_2 <- residuals(lm.fit.ltv.2)^2 %>% sum()
F_12 <- ((RSS_1 - RSS_2)/1) / (RSS_2 / (num_rows_training - 2 - 1))
anova(lm.fit.ltv.1, lm.fit.ltv.2)
lm.fit.ltv.3 <- lm(interest ~ poly(ltv, 3, raw = TRUE), data=fannie_mae_training)
lm.fit.ltv.4 <- lm(interest ~ poly(ltv, 4, raw = TRUE), data=fannie_mae_training)
RSS_3 <- residuals(lm.fit.ltv.3)^2 %>% sum()
RSS_4 <- residuals(lm.fit.ltv.4)^2 %>% sum()
F_23 <- ((RSS_2 - RSS_3)/1) / (RSS_4 / (num_rows_training - 4 - 1))
anova(lm.fit.ltv.1, lm.fit.ltv.2, lm.fit.ltv.3, lm.fit.ltv.4)
# Exploring relationship between interest and LTV
# color palette we will use
color_blind_palette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# Plotting the interest versus LTV
plot(fannie_mae_sample$ltv, fannie_mae_sample$interest, col = "darkgrey", ylab="Interest", xlab="LTV", main = "Interest vs. LTV\n Fitting linear and non-linear models")
# Generating a vector of LTV values for the various models
ltv_lims <- range(fannie_mae_training$ltv)
ltv.grid <- seq(from = ltv_lims[1], to = ltv_lims[2], by = 0.1)
# Linear model plot
preds_lm_1_ltv <- predict(lm.fit.ltv.1, data.frame(ltv=ltv.grid), se = TRUE) # predictions
se_bands_lm_1_ltv <- cbind(preds_lm_1_ltv$fit + 2 * preds_lm_1_ltv$se, preds_lm_1_ltv$fit - 2 * preds_lm_1_ltv$se) # standard error bands
# Plotting predictions and error bands
lines(ltv.grid, preds_lm_1_ltv$fit, col = color_blind_palette[1], lwd = 2)
matlines(ltv.grid, se_bands_lm_1_ltv, col = color_blind_palette[1], lty = 2)
# Quadratic model plot
preds_lm_2_ltv <- predict(lm.fit.ltv.2, data.frame(ltv=ltv.grid), se = TRUE)# predictions
se_bands_lm_2_ltv <- cbind(preds_lm_2_ltv$fit + 2 * preds_lm_2_ltv$se, preds_lm_2_ltv$fit - 2 * preds_lm_2_ltv$se) # standard error bands
# Plotting predictions and error bands
lines(ltv.grid, preds_lm_2_ltv$fit, col = color_blind_palette[2], lwd = 2)
matlines(ltv.grid, se_bands_lm_2_ltv, col = color_blind_palette[2], lty = 2)
# Cubic model plot
preds_lm_3_ltv <- predict(lm.fit.ltv.3, data.frame(ltv=ltv.grid), se = TRUE) # predictions
se_bands_lm_3_ltv <- cbind(preds_lm_3_ltv$fit + 2 * preds_lm_3_ltv$se, preds_lm_3_ltv$fit - 2 * preds_lm_3_ltv$se) # standard error bands
# Plotting predictions and error bands
lines(ltv.grid, preds_lm_3_ltv$fit, col = color_blind_palette[3], lwd = 2)
matlines(ltv.grid, se_bands_lm_3_ltv, col = color_blind_palette[3], lty = 2)
# Quartic model plot
preds_lm_4_ltv <- predict(lm.fit.ltv.4, data.frame(ltv=ltv.grid), se = TRUE) # predictions
se_bands_lm_4_ltv <- cbind(preds_lm_4_ltv$fit + 2 * preds_lm_4_ltv$se, preds_lm_4_ltv$fit - 2 * preds_lm_4_ltv$se) # standard error bands
# Plotting predictions and error bands
lines(ltv.grid, preds_lm_4_ltv$fit, col = color_blind_palette[4], lwd = 2)
matlines(ltv.grid, se_bands_lm_4_ltv, col = color_blind_palette[4], lty = 2)
# Legend: part 1
legend(x = "topleft", legend = c("linear", "quadratic"), lty=c(1,1), lwd = c(2.5,2.5), col = color_blind_palette[1:2])
# Add a fifth order model
lm.fit.ltv.5 <- lm(interest ~ poly(ltv, 5), data=fannie_mae_training)
preds_lm_5_ltv <- predict(lm.fit.ltv.5, data.frame(ltv=ltv.grid), se = TRUE)
se_bands_lm_5_ltv <- cbind(preds_lm_5_ltv$fit + 2 * preds_lm_5_ltv$se, preds_lm_5_ltv$fit - 2 * preds_lm_5_ltv$se)
lines(ltv.grid, preds_lm_5_ltv$fit, col = color_blind_palette[5], lwd = 2)
matlines(ltv.grid, se_bands_lm_5_ltv, col = color_blind_palette[5], lty = 2)
# Legend: part 2
legend(x = "bottomleft", legend = c("cubic", "quartic", "quintic"), inset = c(0.05, 0.0), lty=c(1,1,1), lwd = c(2.5,2.5,2.5), col = color_blind_palette[3:5])
lm.fit.dti.1 <- lm(interest ~ dti, data=fannie_mae_training)
lm.fit.dti.2 <- lm(interest ~ poly(dti, 2, raw = TRUE), data=fannie_mae_training)
lm.fit.dti.3 <- lm(interest ~ poly(dti, 3, raw = TRUE), data=fannie_mae_training)
lm.fit.dti.4 <- lm(interest ~ poly(dti, 4, raw = TRUE), data=fannie_mae_training)
lm.fit.dti.5 <- lm(interest ~ poly(dti, 5, raw = TRUE), data=fannie_mae_training)
anova(lm.fit.dti.1, lm.fit.dti.2, lm.fit.dti.3, lm.fit.dti.4, lm.fit.dti.5)
# Exploring relationship between interest and DTI
# Plotting interest versus DTI
plot(fannie_mae_sample$dti, fannie_mae_sample$interest, col = "darkgrey", ylab="Interest", xlab="DTI", main = "Interest vs. DTI\n Fitting linear and non-linear models")
# Generating a vector of DTI values for the various models
dti_lims <- range(fannie_mae_training$dti)
dti.grid <- seq(from = dti_lims[1], to = dti_lims[2], by = 0.1)
# Linear model plot
preds_lm_1_dti <- predict(lm.fit.dti.1, data.frame(dti=dti.grid), se = TRUE) # predictions
se_bands_lm_1_dti <- cbind(preds_lm_1_dti$fit + 2 * preds_lm_1_dti$se, preds_lm_1_dti$fit - 2 * preds_lm_1_dti$se) # standard error bands
# Plotting predictions and error bands
lines(dti.grid, preds_lm_1_dti$fit, col = color_blind_palette[1], lwd = 2)
matlines(dti.grid, se_bands_lm_1_dti, col = color_blind_palette[1], lty = 2)
# Quadratic model plot
preds_lm_2_dti <- predict(lm.fit.dti.2, data.frame(dti=dti.grid), se = TRUE) # predictions
se_bands_lm_2_dti <- cbind(preds_lm_2_dti$fit + 2 * preds_lm_2_dti$se, preds_lm_2_dti$fit - 2 * preds_lm_2_dti$se) # standard error bands
# Plotting predictions and error bands
lines(dti.grid, preds_lm_2_dti$fit, col = color_blind_palette[2], lwd = 2)
matlines(dti.grid, se_bands_lm_2_dti, col = color_blind_palette[2], lty = 2)
# Cubic model plot
preds_lm_3_dti <- predict(lm.fit.dti.3, data.frame(dti=dti.grid), se = TRUE) # predictions
se_bands_lm_3_dti <- cbind(preds_lm_3_dti$fit + 2 * preds_lm_3_dti$se, preds_lm_3_dti$fit - 2 * preds_lm_3_dti$se) # standard error bands
# Plotting predictions and error bands
lines(dti.grid, preds_lm_3_dti$fit, col = color_blind_palette[3], lwd = 2)
matlines(dti.grid, se_bands_lm_3_dti, col = color_blind_palette[3], lty = 2)
# Quartic model plot
preds_lm_4_dti <- predict(lm.fit.dti.4, data.frame(dti=dti.grid), se = TRUE) # predictions
se_bands_lm_4_dti <- cbind(preds_lm_4_dti$fit + 2 * preds_lm_4_dti$se, preds_lm_4_dti$fit - 2 * preds_lm_4_dti$se) # standard error bands
# Plotting predictions and error bands
lines(dti.grid, preds_lm_4_dti$fit, col = color_blind_palette[4], lwd = 2)
matlines(dti.grid, se_bands_lm_4_dti, col = color_blind_palette[4], lty = 2)
# Quintic model model
preds_lm_5_dti <- predict(lm.fit.dti.5, data.frame(dti=dti.grid), se = TRUE) # predictions
se_bands_lm_5_dti <- cbind(preds_lm_5_dti$fit + 2 * preds_lm_5_dti$se, preds_lm_5_dti$fit - 2 * preds_lm_5_dti$se) # standard error bands
# Plotting predictions and error bands
lines(dti.grid, preds_lm_5_dti$fit, col = color_blind_palette[5], lwd = 2)
matlines(dti.grid, se_bands_lm_5_dti, col = color_blind_palette[5], lty = 2)
# Legends
legend(x = "topleft", legend = c("linear", "quadratic"), lty=c(1,1), lwd = c(2.5,2.5), col = color_blind_palette[1:2])
legend(x = "bottomleft", legend = c("cubic", "quartic", "quintic"), inset = c(0.00, 0.0), lty=c(1,1,1), lwd = c(2.5,2.5,2.5), col = color_blind_palette[3:5])
lm.fit.score.1 <- lm(interest ~ borrower_score, data=fannie_mae_training)
lm.fit.score.2 <- lm(interest ~ poly(borrower_score, 2, raw = TRUE), data=fannie_mae_training)
lm.fit.score.3 <- lm(interest ~ poly(borrower_score, 3, raw = TRUE), data=fannie_mae_training)
lm.fit.score.4 <- lm(interest ~ poly(borrower_score, 4, raw = TRUE), data=fannie_mae_training)
lm.fit.score.5 <- lm(interest ~ poly(borrower_score, 5, raw = TRUE), data=fannie_mae_training)
anova(lm.fit.score.1, lm.fit.score.2, lm.fit.score.3, lm.fit.score.4, lm.fit.score.5)
# Exploring relationship between interest and borrower score
# Plotting interest versus borrower score
plot(fannie_mae_sample$borrower_score, fannie_mae_sample$interest, col = "darkgrey", ylab="Interest", xlab="Borrower credit score", main = "Interest vs. credit score\n Fitting linear and non-linear models")
# Generating a vector of borrower score values for the various models
score_lims <- range(fannie_mae_training$borrower_score)
score.grid <- seq(from = score_lims[1], to = score_lims[2], by = 0.1)
# Linear model plot
preds_lm_1_score <- predict(lm.fit.score.1, data.frame(borrower_score=score.grid), se = TRUE) # predictions
se_bands_lm_1_score <- cbind(preds_lm_1_score$fit + 2 * preds_lm_1_score$se, preds_lm_1_score$fit - 2 * preds_lm_1_score$se) # standard error bands
# Plotting predictions and error bands
lines(score.grid, preds_lm_1_score$fit, col = color_blind_palette[1], lwd = 2)
matlines(score.grid, se_bands_lm_1_score, col = color_blind_palette[1], lty = 2)
# Quadratic model plot
preds_lm_2_score <- predict(lm.fit.score.2, data.frame(borrower_score=score.grid), se = TRUE)# predictions
se_bands_lm_2_score <- cbind(preds_lm_2_score$fit + 2 * preds_lm_2_score$se, preds_lm_2_score$fit - 2 * preds_lm_2_score$se) # standard error bands
# Plotting predictions and error bands
lines(score.grid, preds_lm_2_score$fit, col = color_blind_palette[2], lwd = 2)
matlines(score.grid, se_bands_lm_2_score, col = color_blind_palette[2], lty = 2)
# Cubic model plot
preds_lm_3_score <- predict(lm.fit.score.3, data.frame(borrower_score=score.grid), se = TRUE)# predictions
se_bands_lm_3_score <- cbind(preds_lm_3_score$fit + 2 * preds_lm_3_score$se, preds_lm_3_score$fit - 2 * preds_lm_3_score$se) # standard error bands
# Plotting predictions and error bands
lines(score.grid, preds_lm_3_score$fit, col = color_blind_palette[3], lwd = 2)
matlines(score.grid, se_bands_lm_3_score, col = color_blind_palette[3], lty = 2)
# Quartic model plot
preds_lm_4_score <- predict(lm.fit.score.4, data.frame(borrower_score=score.grid), se = TRUE)# predictions
se_bands_lm_4_score <- cbind(preds_lm_4_score$fit + 2 * preds_lm_4_score$se, preds_lm_4_score$fit - 2 * preds_lm_4_score$se) # standard error bands
# Plotting predictions and error bands
lines(score.grid, preds_lm_4_score$fit, col = color_blind_palette[4], lwd = 2)
matlines(score.grid, se_bands_lm_4_score, col = color_blind_palette[4], lty = 2)
# Quintic model plot
preds_lm_5_score <- predict(lm.fit.score.5, data.frame(borrower_score=score.grid), se = TRUE)# predictions
se_bands_lm_5_score <- cbind(preds_lm_5_score$fit + 2 * preds_lm_5_score$se, preds_lm_5_score$fit - 2 * preds_lm_5_score$se) # standard error bands
# Plotting predictions and error bands
lines(score.grid, preds_lm_5_score$fit, col = color_blind_palette[5], lwd = 2)
matlines(score.grid, se_bands_lm_5_score, col = color_blind_palette[5], lty = 2)
# Legends
legend(x = "topleft", legend = c("linear", "quadratic"), lty=c(1,1), lwd = c(2.5,2.5), col = color_blind_palette[1:2])
legend(x = "bottomleft", legend = c("cubic", "quartic", "quintic"), inset = c(0.00, 0.0), lty=c(1,1,1), lwd = c(2.5,2.5,2.5), col = color_blind_palette[3:5])
lm.fit.balance.1 <- lm(interest ~ balance, data=fannie_mae_training)
lm.fit.balance.2 <- lm(interest ~ poly(balance, 2, raw = TRUE), data=fannie_mae_training)
lm.fit.balance.3 <- lm(interest ~ poly(balance, 3, raw = TRUE), data=fannie_mae_training)
lm.fit.balance.4 <- lm(interest ~ poly(balance, 4, raw = TRUE), data=fannie_mae_training)
lm.fit.balance.5 <- lm(interest ~ poly(balance, 5, raw = TRUE), data=fannie_mae_training)
anova(lm.fit.balance.1, lm.fit.balance.2, lm.fit.balance.3, lm.fit.balance.4, lm.fit.balance.5)
# Plotting interest versus original loan balance
plot(fannie_mae_sample$balance, fannie_mae_sample$interest, col = "darkgrey", ylab="Interest", xlab="Original loan balance", main = "Interest vs. original loan balance\n Fitting linear and non-linear models")
# Generating a vector of loan balance values for the various models
balance_lims <- range(fannie_mae_training$balance)
balance.grid <- seq(from = balance_lims[1], to = balance_lims[2], by = 1000)
# Linear model plot
preds_lm_1_balance <- predict(lm.fit.balance.1, data.frame(balance=balance.grid), se = TRUE) # predictions
se_bands_lm_1_balance <- cbind(preds_lm_1_balance$fit + 2 * preds_lm_1_balance$se, preds_lm_1_balance$fit - 2 * preds_lm_1_balance$se) # standard error bands
# Plotting predictions and error bands
lines(balance.grid, preds_lm_1_balance$fit, col = color_blind_palette[1], lwd = 2)
matlines(balance.grid, se_bands_lm_1_balance, col = color_blind_palette[1], lty = 2)
# Quadratic model plot
preds_lm_2_balance <- predict(lm.fit.balance.2, data.frame(balance=balance.grid), se = TRUE) # predictions
se_bands_lm_2_balance <- cbind(preds_lm_2_balance$fit + 2 * preds_lm_2_balance$se, preds_lm_2_balance$fit - 2 * preds_lm_2_balance$se) # standard error bands
# Plotting predictions and error bands
lines(balance.grid, preds_lm_2_balance$fit, col = color_blind_palette[2], lwd = 2)
matlines(balance.grid, se_bands_lm_2_balance, col = color_blind_palette[2], lty = 2)
# Cubic model plot
preds_lm_3_balance <- predict(lm.fit.balance.3, data.frame(balance=balance.grid), se = TRUE) # predictions
se_bands_lm_3_balance <- cbind(preds_lm_3_balance$fit + 2 * preds_lm_3_balance$se, preds_lm_3_balance$fit - 2 * preds_lm_3_balance$se) # standard error bands
# Plotting predictions and error bands
lines(balance.grid, preds_lm_3_balance$fit, col = color_blind_palette[3], lwd = 2)
matlines(balance.grid, se_bands_lm_3_balance, col = color_blind_palette[3], lty = 2)
# Quartic model plot
preds_lm_4_balance <- predict(lm.fit.balance.4, data.frame(balance=balance.grid), se = TRUE) # predictions
se_bands_lm_4_balance <- cbind(preds_lm_4_balance$fit + 2 * preds_lm_4_balance$se, preds_lm_4_balance$fit - 2 * preds_lm_4_balance$se) # standard error bands
# Plotting predictions and error bands
lines(balance.grid, preds_lm_4_balance$fit, col = color_blind_palette[4], lwd = 2)
matlines(balance.grid, se_bands_lm_4_balance, col = color_blind_palette[4], lty = 2)
# Quintic model plot
preds_lm_5_balance <- predict(lm.fit.balance.5, data.frame(balance=balance.grid), se = TRUE) # predictions
se_bands_lm_5_balance <- cbind(preds_lm_5_balance$fit + 2 * preds_lm_5_balance$se, preds_lm_5_balance$fit - 2 * preds_lm_5_balance$se) # standard error bands
# Plotting predictions and error bands
lines(balance.grid, preds_lm_5_balance$fit, col = color_blind_palette[5], lwd = 2)
matlines(balance.grid, se_bands_lm_5_balance, col = color_blind_palette[5], lty = 2)
# Legends
legend(x = "bottomright", inset = c(0.2, 0.0), legend = c("linear", "quadratic"), lty=c(1,1), lwd = c(2.5,2.5), col = color_blind_palette[1:2])
legend(x = "bottomright", legend = c("cubic", "quartic", "quintic"), inset = c(0.00, 0.0), lty=c(1,1,1), lwd = c(2.5,2.5,2.5), col = color_blind_palette[3:5])
lm.fit.non_linear <- lm(interest ~ poly(balance, 3, raw = TRUE) + poly(dti, 5, raw = TRUE) + poly(ltv, 5, raw = TRUE) + poly(borrower_score, 2, raw = TRUE) + poly(co_borrower_score, 3, raw = TRUE) + purpose + property_type + relocation + first_time, data = fannie_mae_training )
summary(lm.fit.non_linear)
# Predictions vector
predict_interest_test_nonlin <- predict(lm.fit.non_linear, newdata = fannie_mae_test)
# Compute RSS on test set
RSS_test_nonlin <- (fannie_mae_test$interest - predict_interest_test_nonlin)^2 %>% sum()
# TSS_test does not change
# Compute R_sqrd
R_sqrd_test_nonlin <- 1 - RSS_test_nonlin / TSS_test
# Compute RSS, R_sqrd, and MSE on training set
RSS_nonlin <- residuals(lm.fit.non_linear)^2 %>% sum()
R_sqrd_nonlin <- 1 - RSS_nonlin / TSS
MSE_nonlin <- RSS_nonlin / num_rows_training
# Compute MSE on test set
MSE_test_nonlin <- RSS_test_nonlin / num_rows_test
hist(fannie_mae_sample$dti, xlab = "", ylab = "", main = "DTI histogram", col = "red")
residuals(lm.fit.linear) %>% hist(col = "darkgrey")
residuals(lm.fit.linear) %>% hist(col = "darkgrey")
residuals(lm.fit.linear) %>% hist(col = "darkgrey")
legend(x = "topleft", legend = c("linear", "quadratic"))
residuals(lm.fit.linear) %>% hist(col = "darkgrey")
legend(x = "topleft", legend = c(paste("mean =", mean(residuals(lm.fit.linear)))))
residuals(lm.fit.linear) %>% hist(col = "darkgrey")
legend(x = "topleft", legend = c(paste("mean =", mean(residuals(lm.fit.linear)))))
grid()
residuals(lm.fit.linear) %>% hist(col = "darkgrey", main = "Histogram of linear model residuals")
legend(x = "topleft", legend = c(paste("mean =", mean(residuals(lm.fit.linear)))))
grid()
?round
residuals(lm.fit.linear) %>% hist(col = "darkgrey", main = "Histogram of linear model residuals")
legend(x = "topleft", legend = c(paste("mean =", mean(signif(residuals(lm.fit.linear))))))
grid()
residuals(lm.fit.linear) %>% hist(col = "darkgrey", main = "Histogram of linear model residuals")
legend(x = "topleft", legend = c(paste("mean =", mean(residuals(lm.fit.linear)))))
grid()
x2 <- pi * 100^(-1:3)
x2
round(x2,3)
signif(x2,3)
residuals(lm.fit.linear) %>% hist(col = "darkgrey", main = "Histogram of linear model residuals")
legend(x = "topleft", legend = c(paste("mean =", mean(signif(residuals(lm.fit.linear), 4)))))
grid()
residuals(lm.fit.linear) %>% hist(col = "darkgrey", main = "Histogram of linear model residuals")
legend(x = "topleft", legend = c(paste("mean =", mean(signif(residuals(lm.fit.linear), 2)))))
grid()
residuals(lm.fit.linear) %>% hist(col = "darkgrey", main = "Histogram of linear model residuals")
legend(x = "topleft", legend = c(paste("mean =", mean(residuals(lm.fit.linear)))))
grid()
residuals(lm.fit.linear) %>% hist(col = "darkgrey", main = "Histogram of linear model residuals")
legend(x = "topleft", legend = c(paste("mean =", signif(mean(residuals(lm.fit.linear))))))
grid()
residuals(lm.fit.linear) %>% hist(col = "lightgrey", main = "Histogram of linear model residuals")
legend(x = "topleft", legend = c(paste("mean =", signif(mean(residuals(lm.fit.linear))))))
grid()
residuals(lm.fit.linear) %>% hist(col = "lightgrey", main = "Histogram of linear model residuals", xlab = "Residuals of linear model")
legend(x = "topleft", legend = c(paste("mean =", signif(mean(residuals(lm.fit.linear))))))
grid()
library(lmtest)
bptest.linear <- bptest(lm.fit.linear)
bptest.linear
summary(bptest.linear)
str(bptest.linear)
bptest.linear$statistic
bptest.linear$parameter
# Performing the auxiliary regression for the BP test
lm.fit.linear.residuals.squared <- lm(linear_model_residuals^2 ~ balance + dti + ltv + borrower_score + co_borrower_score + purpose + property_type + relocation + first_time, data = fannie_mae_training)
# Computing the test statistic
R_aux_sqrd <- summary(lm.fit.linear.residuals.squared)$r.squared
BP_test_statistic <- length(linear_model_residuals) * R_aux_sqrd
pchisq(BP_test_statistic, df = 13, lower.tail = FALSE)
# Plotting the distributions of the quantitative predictors
par(mfrow=c(2,2))
hist(fannie_mae_sample$borrower_score, xlab = "", ylab = "", main = "Borrower score histogram", col = "lightgrey")
hist(fannie_mae_sample$ltv, xlab = "", ylab = "", main = "LTV histogram")
hist(fannie_mae_sample$dti, xlab = "", ylab = "", main = "DTI histogram")
hist(fannie_mae_sample$balance, xlab = "", ylab = "", main = "Loan balance histogram")
# Plotting the distributions of the quantitative predictors
par(mfrow=c(2,2))
hist(fannie_mae_sample$borrower_score, xlab = "", ylab = "", main = "Borrower score histogram", col = "lightgrey")
hist(fannie_mae_sample$ltv, xlab = "", ylab = "", main = "LTV histogram", col = "lightgrey")
hist(fannie_mae_sample$dti, xlab = "", ylab = "", main = "DTI histogram", col = "lightgrey")
hist(fannie_mae_sample$balance, xlab = "", ylab = "", main = "Loan balance histogram", col = "lightgrey")
# Plotting the response as a function of the qualitative predictors
par(mfrow=c(2,2))
boxplot(fannie_mae_sample$interest ~ fannie_mae_sample$purpose, main = "Interest vs. loan purpose", sub = "C = Cash-out refi P = Purchase R = No-cash-out refi", col = "lightgrey"); grid()
boxplot(fannie_mae_sample$interest ~ fannie_mae_sample$property_type, main = "Interest vs. property type", sub = "SF = Single Family CO = Condo MH = Manufactured\n PU = Planned Urban Development CP = Co-op"); grid()
boxplot(fannie_mae_sample$interest ~ fannie_mae_sample$relocation, main = "Interest vs. relocation indicator"); grid()
boxplot(fannie_mae_sample$interest ~ fannie_mae_sample$first_time, main = "Interest vs. first-time buyer indicator"); grid()
# Plotting the response as a function of the qualitative predictors
par(mfrow=c(2,2))
boxplot(fannie_mae_sample$interest ~ fannie_mae_sample$purpose, main = "Interest vs. loan purpose", sub = "C = Cash-out refi P = Purchase R = No-cash-out refi", col = "lightgrey"); grid()
boxplot(fannie_mae_sample$interest ~ fannie_mae_sample$property_type, main = "Interest vs. property type", sub = "SF = Single Family CO = Condo MH = Manufactured\n PU = Planned Urban Development CP = Co-op", col = "lightgrey"); grid()
boxplot(fannie_mae_sample$interest ~ fannie_mae_sample$relocation, main = "Interest vs. relocation indicator", col = "lightgrey"); grid()
boxplot(fannie_mae_sample$interest ~ fannie_mae_sample$first_time, main = "Interest vs. first-time buyer indicator", col = "lightgrey"); grid()
# Plotting the distributions of the quantitative predictors
par(mfrow=c(2,2))
hist(fannie_mae_sample$borrower_score, xlab = "", ylab = "", main = "Borrower score histogram", col = "lightgrey"); grid()
hist(fannie_mae_sample$ltv, xlab = "", ylab = "", main = "LTV histogram", col = "lightgrey")
hist(fannie_mae_sample$dti, xlab = "", ylab = "", main = "DTI histogram", col = "lightgrey")
hist(fannie_mae_sample$balance, xlab = "", ylab = "", main = "Loan balance histogram", col = "lightgrey")
# Plotting the distributions of the quantitative predictors
par(mfrow=c(2,2))
hist(fannie_mae_sample$borrower_score, xlab = "", ylab = "", main = "Borrower score histogram", col = "lightgrey"); grid()
hist(fannie_mae_sample$ltv, xlab = "", ylab = "", main = "LTV histogram", col = "lightgrey"); grid()
hist(fannie_mae_sample$dti, xlab = "", ylab = "", main = "DTI histogram", col = "lightgrey"); grid()
hist(fannie_mae_sample$balance, xlab = "", ylab = "", main = "Loan balance histogram", col = "lightgrey"); grid()
library(caTools)
# set.seed(1000) # reproducibility
# split <- sample.split(th$Severity, SplitRatio = 0.7)
# mammo_data_train <- subset(mammo_data, split==TRUE)
# mammo_data_test <- subset(mammo_data, split==FALSE)
?sample.split
library(MASS)
data(cats)
cats
summary(cats)
thyroid <- read.csv("thyroid.dat", header = FALSE, skip = 26)
colnames(thyroid) <- c("age", "sex", "on_thyroxine", "query_on_thyroxine", "antithyroid_medication", "sick", "pregnant", "thyroid_surgery", "I131_treatment", "query_hypothyroid", "query_hyperthyroid", "lithium", "goitre", "tumor", "hypopituitary", "psych", "TSH", "T3", "TT4", "T4U", "FTI","class")
str(thyroid)
split <- sample.split(thyroid$class, SplitRatio = 0.7)
?split
data_split <- sample.split(thyroid$class, SplitRatio = 0.7)
?data_split
summary(data_split)
summary(thyroid$class)
table(thyroid$class)
thyroid_train <- subset(thyroid, split==TRUE)
table(thyroid_train$class)
6666*0.7
368*0.7
166*.7
?read.csv
thyroid <- read.csv("thyroid.dat", header = FALSE, skip = 26)
colnames(thyroid) <- c("age", "sex", "on_thyroxine", "query_on_thyroxine", "antithyroid_medication", "sick", "pregnant", "thyroid_surgery", "I131_treatment", "query_hypothyroid", "query_hyperthyroid", "lithium", "goitre", "tumor", "hypopituitary", "psych", "TSH", "T3", "TT4", "T4U", "FTI","class")
str(thyroid)
# Changle "class" to factor
thyroid$class <- factor(thyroid$class)
# Multiply "age" by 100
thyroid$age <- 100 * thyroid$age
library(caTools)
set.seed(1000) # reproducibility
split <- sample.split(thyroid$class, SplitRatio = 0.7)
thyroid_train <- subset(thyroid, split==TRUE)
thyroid_test <- subset(thyroid, split==FALSE)
library(rpart)
library(rpart.plot)
# Building a tree with a minimum of 10 observations on each leaf
thyroid_tree <- rpart(class ~ ., data = thyroid_train, control=rpart.control(minbucket=50))
prp(thyroid_tree)
# Building a tree with a minimum of 10 observations on each leaf
thyroid_tree <- rpart(class ~ ., data = thyroid_train, control=rpart.control(minbucket=10))
prp(thyroid_tree)
# Building a tree with a minimum of 10 observations on each leaf
thyroid_tree <- rpart(class ~ ., data = thyroid_train, control=rpart.control(minbucket=1))
prp(thyroid_tree)
table(thyroid$on_thyroxine)
table(thyroid$query_on_thyroxine)
table(thyroid$query_hypothyroid)
table(thyroid$query_hyperthyroid)
table(thyroid$antithyroid_medication)
table(thyroid$sick)
table(thyroid$pregnant)
table(thyroid$thyroid_surgery)
table(thyroid$I131_treatment)
table(thyroid$query_hypothyroid)
table(thyroid$query_hyperthyroid)
table(thyroid$lithium)
table(thyroid$goitre)
table(thyroid$tumor)
summary(thyroid)
thyroid <- read.csv("thyroid.dat", header = FALSE, skip = 26) # skipping the first 26 lines
colnames(thyroid) <- c("age", "sex", "on_thyroxine", "query_on_thyroxine", "antithyroid_medication", "sick", "pregnant", "thyroid_surgery", "I131_treatment", "query_hypothyroid", "query_hyperthyroid", "lithium", "goitre", "tumor", "hypopituitary", "psych", "TSH", "T3", "TT4", "T4U", "FTI","class")
str(thyroid)
# Changle "class" to factor
thyroid$class <- factor(thyroid$class)
# Multiply "age" by 100
thyroid$age <- 100 * thyroid$age
library(caTools)
set.seed(1000) # reproducibility
split <- sample.split(thyroid$class, SplitRatio = 0.7)
thyroid_train <- subset(thyroid, split==TRUE)
thyroid_test <- subset(thyroid, split==FALSE)
library(rpart)
library(rpart.plot)
# Building a tree with a minimum of 10 observations on each leaf
thyroid_tree <- rpart(class ~ ., data = thyroid_train, control=rpart.control(minbucket=1))
prp(thyroid_tree)
# Building a tree with a minimum of 10 observations on each leaf
thyroid_tree <- rpart(class ~ ., data = thyroid_train, control=rpart.control(minbucket=50))
prp(thyroid_tree)
# Generate predictions on training set
PredictCART_train = predict(thyroid_tree, type = "class")
# Confusion matrix of training set
conf_matrix_train <- table(thyroid_train$class, PredictCART_train)
conf_matrix_train
sum(diag(conf_matrix_train)) / sum(conf_matrix_train)
PredictCART_test = predict(thyroid_tree, newdata = thyroid_test, type = "class")
# Confusion matrix of test set
conf_matrix_test <- table(thyroid_test$class, PredictCART_test)
conf_matrix_test
sum(diag(conf_matrix_test)) / sum(conf_matrix_test)
library(caret)
library(e1071)
# Setting cross-validation to be 10-fold
fitControl = trainControl( method = "cv", number = 10 )
# Setting cp to .01, .02, ..., 0.5
cartGrid = expand.grid( .cp = (1:50)*0.01)
train(class ~ ., data = thyroid_train, method = "rpart", trControl = fitControl, tuneGrid = cartGrid)
thyroid_tree_cv <- rpart(class ~ ., data = thyroid_train, control=rpart.control(cp=0.03))
prp(thyroid_tree_cv)
# Generate predictions on training set
PredictCART_train_cv = predict(thyroid_tree_cv, type = "class")
# Confusion matrix of training set
conf_matrix_train_cv <- table(thyroid_train$class, PredictCART_train_cv)
conf_matrix_train_cv
# Generate predictions on training set
PredictCART_train_cv = predict(thyroid_tree_cv, type = "class")
# Confusion matrix of training set
conf_matrix_train_cv <- table(thyroid_train$class, PredictCART_train_cv)
conf_matrix_train_cv
sum(diag(conf_matrix_train_cv)) / sum(conf_matrix_train_cv)
# Generate predictions on test set using cross-validated set
PredictCART_test_cv = predict(thyroid_tree_cv, type = "class")
# Confusion matrix of training set
conf_matrix_test_cv <- table(thyroid_test$class, PredictCART_test_cv)
# Generate predictions on test set using cross-validated set
PredictCART_test_cv = predict(thyroid_tree_cv, newdat = thyroid_test, type = "class")
# Confusion matrix of training set
conf_matrix_test_cv <- table(thyroid_test$class, PredictCART_test_cv)
conf_matrix_test_cv
sum(diag(conf_matrix_test_cv)) / sum(conf_matrix_test_cv)
?plot
install.packages("jpeg")
library(jpeg)
setwd("~/")
img <- readJPEG(system.file("img", "999.jpg", package="jpeg"))
img <- readJPEG(system.file("img", "0999.jpg", package="jpeg"))
getcwd()
getwd()
img <- readJPEG(system.file("img", "0999.jpg", package="jpeg"))
img <- readJPEG(system.file("img", "0999.jpg", package="jpeg"))
img <- readJPEG(system.file("img", "0999.jpg", package="jpeg"))
?readJPEG
img <- readJPEG(system.file("img", "0999.JPG", package="jpeg"))
img <- readJPEG("0999.jpg")
str(img)
plot(img)
?clearNames
?clear
img <- readJPEG("0999_gray.jpg")
str(img)
img[1,1]
?dim
dim(img)
img[1,]
img[10,]
img[148,]
q()
library(wordcloud2)
figPath = system.file("examples/t.png",package = "wordcloud2")
wordcloud2(demoFreq, figPath = figPath, size = 1.5,color = "skyblue")
wordcloud2(demoFreq, figPath = figPath, size = 1.5,color = "skyblue")
library(devtools)
devtools::install_github("lchiffon/wordcloud2")
library(wordcloud2)
wordcloud2(demoFreq, figPath = figPath, size = 1.5,color = "skyblue")
figPath = system.file("examples/t.png",package = "wordcloud2")
wordcloud2(demoFreq, figPath = figPath, size = 1.5,color = "skyblue")
setwd("./Boricuas_NCAA/Season_Summary_2019_2020/Women/Articles/Lina_Bernier_Article/")
source("Bernier_heights_barplot_3.r")
